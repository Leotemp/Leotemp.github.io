---
title: "Exploit Multiple Reference Graphs for Semi-Supervised Relation Extraction"
subtitle: "Arxiv-2020"
date: 2021-03-13T12:50:10+08:00
draft: false
tags: ["关系抽取", "半监督学习"]
katex: true
---

**Exploit Multiple Reference Graphs for Semi-Supervised Relation Extraction** [[paper]](https://arxiv.org/abs/2010.11383)

本文是针对上文的**DualRE**的改进工作, 加入了一些人工特征信息, 在半监督关系抽取上取得了SOTA的结果, 但遗憾的是缺乏足够的理论分析, 实验也不够充分.

### Motivation

**DualRE**使用在有监督样本上预训练的模型对无标签样本进行预测, 要求有监督样本和无监督样本的分布一致.
当两种数据之间的语义鸿沟较大时, **DualRE**的性能会受到限制.

为了解决这个问题, 本文通过构造人工特征, 建立起有监督样本和无监督样本之间的联系.

`个人认为这段对DualRE的阐述比较勉强, 而且本文虽然建立起了两种数据之间的联系, 但并没有从根本上解决有/无监督样本之间的语义鸿沟.`

### Model

![模型框架图](/images/li2020exploit.png)

模型从下到上可以分为四部分:

1. **Input Module**
   
   构造三个不同的特征图, 用来连接有监督样本和无监督样本.
   这些图都是二分图, 每个节点表示一个句子, 而每条边连接一个有标注句子和一个无标注句子.
   三个图中连边的规则如下:
   * **实体参考图**: 如果两个句子包含相同的目标实体, 则连边
   * **动词参考图**: 如果两个句子的目标实体对之间的动词相同, 则连边
   * **语义参考图**: 如果两个句子向量的余弦相似度大于阈值, 则连边 (句子向量来自于Prediction Module中的Encoder)

2. **Prediction Module**
   
   一个Encoder和一个Classifier, 用有监督样本进行训练, 然后对无监督样本进行分类. 

3. **Graph Update Module**
   
   将增强后的样本(即得到伪标签的无监督样本)作为有监督的节点, 更新上述三个图, 并且用上一步中更新后的encoder来更新句子向量.

   `这里疑惑的是, 增强样本是指从Prediction Module中选出一部分高置信度的无监督样本, 还是上一轮迭代结束后得到的伪标签样本? 如果是前者的话, 是怎么选择的? 如果是后者的话, 在每轮的Input Module中不是已经将这些样本加入有监督集合了么?`

4. **Multi GAT Module**

    本模块分为三个部分: 
    * 使用3个GAT分别对3个图进行编码
    * 通过注意力机制为每个节点计算在三个图上的注意力加权和
    * 使用Classifier, 对无监督节点进行分类

最终取2和4中的分类结果的交集作为一轮迭代中选取的高置信度样本, 加入到有监督训练集中.
    

### Experiments

在**SemEval**和**TACRED**上取得了SOTA的结果. 

消融学习中展示了三个特征图的影响, **动词参考图** > **实体参考图** > **语义参考图**.

`个人感觉模型还可以进一步精简, 尤其是Prediction Module略显冗余, 这部分是不是必须的? DualRE中两个模块正好互为补充, 而本模型里Prediction Module和MGAT的联系并没有这么紧密. 遗憾的是原文并没有给出该模块的消融分析`