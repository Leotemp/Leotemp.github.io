<?xml version="1.0" encoding="utf-8"?>






<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>九月</title>
        <link>https://tmliang.github.io/</link>
        <description>记录我的科研生活</description>
        <generator>Hugo 0.81.0 https://gohugo.io/</generator>
        
            <language>zh-CN</language>
        
        
            <managingEditor>tm.liang@outlook.com (Liang Tianming)</managingEditor>
        
        
            <webMaster>tm.liang@outlook.com (Liang Tianming)</webMaster>
        
        
            <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
        
        <lastBuildDate>Tue, 13 Apr 2021 13:40:09 &#43;0800</lastBuildDate>
        
            <atom:link rel="self" type="application/rss&#43;xml" href="https://tmliang.github.io/rss.xml" />
        
        
            <item>
                <title>sudo chmod 700 /* 补救措施</title>
                <link>https://tmliang.github.io/research/sudo_chmod_700_%E8%A1%A5%E6%95%91/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/sudo_chmod_700_%E8%A1%A5%E6%95%91/</guid>
                <pubDate>Tue, 13 Apr 2021 13:01:36 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;今天使用&lt;code&gt;sudo chmod 700 ./*&lt;/code&gt;修改文件权限的时候, 不小心少打了一个&lt;code&gt;.&lt;/code&gt;, 变成了&lt;code&gt;sudo chmod 700 /*&lt;/code&gt;, 导致所有文件都无法访问, 所有命令都使用不了.&lt;/p&gt;
&lt;p&gt;在&lt;a href=&#34;https://www.reddit.com/r/linuxquestions/comments/c578cl/accidentally_did_sudo_chmod_700/&#34;&gt;Reddit&lt;/a&gt;上找到解决方案, 通过&lt;code&gt;sudo su&lt;/code&gt;登陆为root, 然后把权限改回来.&lt;/p&gt;
&lt;p&gt;然而现在所有的命令我都用不了, 包括&lt;code&gt;sudo&lt;/code&gt;. 于是直接打开服务器主机, 在本地进行修改, 但是在服务器上, 登录页面都出不来. 最后想到, 可以直接通过&lt;code&gt;recovery mode&lt;/code&gt;, 以root身份登录命令行, 进而恢复文件权限.&lt;/p&gt;
&lt;h4 id=&#34;具体步骤&#34;&gt;具体步骤:&lt;/h4&gt;
&lt;p&gt;如果是以root用户来运行&lt;code&gt;sudo chmod 700 ./*&lt;/code&gt;的, 直接以root身份恢复文件权限即可 (见3). 如果遇到上述情况(即sudo命令无法使用, 也无法通过root登录), 重启服务器, 执行下述步骤.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;进入GNU GRUB界面 (开机一直按着&lt;code&gt;Shift&lt;/code&gt;键, 或者BIOS引导界面之后按&lt;code&gt;Esc&lt;/code&gt;建), 选择&lt;code&gt;Advanced options for Ubuntu&lt;/code&gt;, 回车.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-04-13-1.png&#34; alt=&#34;GNU GRUB&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择最新版本的&lt;code&gt;recovery mode&lt;/code&gt;, 回车&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-04-13-2.png&#34; alt=&#34;recovery mode&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择&lt;code&gt;root Drop to root shell prompt&lt;/code&gt;, 回车, 即可以root身份登录命令行.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-04-13-3.png&#34; alt=&#34;root&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;输入如下指令, 恢复文件权限.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; chmod 755 $(find / -maxdepth 1 -type d)
 chmod 777 $(find / -maxdepth 1 -type l)
 chmod 777 /tmp
 chmod 750 /root
 chmod 700 /lost+found
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;输入&lt;code&gt;reboot&lt;/code&gt;重启.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/linux/">linux</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Memory Networks 系列模型梳理</title>
                <link>https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/</guid>
                <pubDate>Sun, 14 Mar 2021 10:32:06 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;本文对Memory Networks系列文章进行总结, 为了不局限于在某个领域的应用, 不赘述模型的具体操作步骤, 而对该系列模型的中心思想角度进行梳理.&lt;/p&gt;
&lt;p&gt;传统的神经网络模型(如CNN、RNN)等使用隐藏层来记忆所有的训练数据信息, 这种做法存在以下不足:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多个隐藏层的堆叠, 使得输出的表示过于抽象, 难以表示原有数据的全部信息&lt;/li&gt;
&lt;li&gt;经过多次迭代更新后, 模型只能记住训练数据主要的抽象特征, 长尾数据往往会被遗忘&lt;/li&gt;
&lt;li&gt;模型的计算过程可以被设计, 但其记忆过程却不受人为控制. 训练集的偏差可能被模型认为是重要特征&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述不足的原因都可以归咎于传统神经网络过小的记忆容量. 为此, Memory Networks被提出, 跟传统神经网络不同的是, 它使用外部的记忆单元来显式存储所需要记忆的信息, 并通过读写操作来实现对记忆单元的更新.
&lt;strong&gt;传统神经网络可以看作是一块CPU, 推理运算能力极强, 却只能使用容量极小的Cache来存储信息. 而Memory Networks则是CPU搭配内存, CPU负责推理运算, 内存用于存储大规模的信息, 两者各司其职.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;memory-networks&#34;&gt;Memory Networks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Memory Networks (ICLR-2015)&lt;/strong&gt; &lt;a href=&#34;https://arxiv.org/abs/1410.3916&#34;&gt;[paper]&lt;/a&gt;
&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-1.png&#34; alt=&#34;Memory Networks&#34;&gt;&lt;/p&gt;
&lt;p&gt;如图, Memory Networks由一个记忆单元M和4个计算模块I、G、O、R组成.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Memory (M)&lt;/strong&gt;: 外部记忆单元, 通过内部的N个Memory Slots (m&lt;sub&gt;1&lt;/sub&gt;, ..., m&lt;sub&gt;N&lt;/sub&gt;) 来存储信息 (N可以非常大)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Input (I)&lt;/strong&gt;: 将输入X编码为向量形式&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generalization (G)&lt;/strong&gt;: 将输入X中所需记忆的信息写入M&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output (O)&lt;/strong&gt;: 根据输入X, 从M中读取所需的信息&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Response (R)&lt;/strong&gt;: 对O的输出进行解码, 得到模型的输出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更为常见的形式是用于QA问答中(如下图), 其输入是一段参考文本X和一个问题q, 要求模型从X中得到q的答案.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-2.png&#34; alt=&#34;Memory Networks on QA&#34;&gt;&lt;/p&gt;
&lt;p&gt;在之前解读的文章&lt;a href=&#34;https://tmliang.github.io/research/effective-deep-memory-networks-for-distant-supervised-relation-extraction/&#34;&gt;&lt;strong&gt;Effective Deep Memory Networks for Distant Supervised Relation Extraction&lt;/strong&gt;&lt;/a&gt;中, 使用的就是这个形式的模型.
在该模型中, 以目标实体对作为q, 以上下文单词作为X.&lt;/p&gt;
&lt;h3 id=&#34;end-to-end-memory-networks&#34;&gt;End-To-End Memory Networks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;End-To-End Memory Networks (NIPS-2015)&lt;/strong&gt; &lt;a href=&#34;https://dl.acm.org/doi/abs/10.5555/2969442.2969512&#34;&gt;[paper]&lt;/a&gt;
&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-3.png&#34; alt=&#34;End-To-End Memory Networks&#34;&gt;&lt;/p&gt;
&lt;p&gt;主要介绍本模型对于前一个Memory Networks在想法上的改进:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;QKV形式的注意力机制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如上图(a)所示, M中通过Key-Value形式(即图中的Input和Output模块)对信息进行存储.
使用q来查询M的输出时, 采用的就是QKV形式的注意力计算.
按照原文的说法, 这种加权和的形式比原先的递归计算形式更利于反向传播.
但本质上, 将m划分为key和value两个部分, key用于查询与query的相关程度, 而value则用于存储记忆内容, 两个部分各司其职, 分别负责推理与记忆, 使得模型更容易学习, 可解释性也更强.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多层记忆单元 (Multi-hop)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如上图(b)所示, 记忆单元从单层被扩展到多层. 通过多层的QKV计算得到最终的输出.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由此也可以看出, 这时候的多层QKV注意力机制已经出现了&lt;code&gt;Attention is all you need&lt;/code&gt;的雏形了 (差别在于MLP、multi-head和self-attention).
💥罗马果然不是一天建成的.&lt;/p&gt;
&lt;h3 id=&#34;key-value-memory-networks&#34;&gt;Key-Value Memory Networks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Key-Value Memory Networks for Directly Reading Documents (ACL-2016)&lt;/strong&gt; &lt;a href=&#34;https://www.aclweb.org/anthology/D16-1147.pdf&#34;&gt;[paper]&lt;/a&gt;
&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-4.png&#34; alt=&#34;Key-Value Memory Networks&#34;&gt;&lt;/p&gt;
&lt;p&gt;其实本模型的KV Memory, 在前一个End-To-End Memory Networks中已经出现了, 只是在前一个模型中被定义为Input-Output, 而在本模型中正式命名为Key-Value.
主要的区别在于, End-To-End Memory Networks中的key和value都来自于同样的输入, 只是经过不同的Embedding矩阵(类似于Transformer).
而Key-Value Memory Networks是为了更加直接地引进外部知识(如文本、知识库等)而设计的, 其key和value可以根据知识形式的设计, 来自于不同的输入(最简单的例子, key表示文本标题, 而value表示文本内容).&lt;/p&gt;
&lt;h3 id=&#34;dynamic-memory-networks&#34;&gt;Dynamic Memory Networks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ask Me Anything: Dynamic Memory Networks for Natural Language Processing (JMLR-2016)&lt;/strong&gt; &lt;a href=&#34;http://proceedings.mlr.press/v48/kumar16.pdf&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本模型主要是针对End-To-End Memory Networks的改进, 之前的Memory Networks每层中的记忆值都是固定的(通过对Text进行Embedding得到, 与Question无关), 而本模型借助RNN模型的递归输出机制, 可以根据Question的不同而得到不同的记忆值, 故谓之&lt;strong&gt;动态记忆&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-5.png&#34; alt=&#34;Dynamic Memory Networks&#34;&gt;&lt;/p&gt;
&lt;p&gt;个人感觉原文对于计算过程的描述过于繁杂(主要是公式符号与图示不一致), 下边简单介绍一下记忆模块中的计算过程. 其中最重要的记忆模块(Episodic Memory Module)可以看作是多层GRU.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mathbf{e}^i_t$表示GRU的第$i$层第$t$步的隐藏层参数($\mathbf{e}^0_t=\mathbf{s}_t$, 其中$\mathbf{s}_t$表示第$t$条句子在Input Module中得到的嵌入)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\mathbf{m}^i=\mathbf{e}^i_T$(即第$i$层最后一步的隐藏层输出)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\mathbf{q}$表示输入的问题的嵌入.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第i层第t步的门控值&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$g^i_t = G(\mathbf{e}^{i-1}_t, \mathbf{m}^{i-1}, \mathbf{q})$$&lt;/p&gt;
&lt;p&gt;其中$G$为特征拼接后经过两层MLP和sigmoid归一化的门控函数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第i层第t步的隐藏层&lt;/strong&gt;:
$$\mathbf{e}^i_t = g^i_t \cdot GRU(\mathbf{e}^{i-1}_t, \mathbf{e}^i_{t-1}) + (1 - g^i_t) \cdot \mathbf{e}^i_{t-1}$$&lt;/p&gt;
&lt;h3 id=&#34;recurrent-entity-networks&#34;&gt;Recurrent Entity Networks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Tracking the World State with Recurrent Entity Networks (ICLR-2017)&lt;/strong&gt; &lt;a href=&#34;https://arxiv.org/abs/1612.03969&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前述的所有Memory Networks, 存储的都是当前的输入, 而并没有像内存一样, 长期地记忆真实世界里的一些东西.
而这正是Recurrent Entity Networks创新的地方, 它的每个记忆单元都对应真实世界里的一个实体, 记忆单元之间相互独立, key用于标识实体, value则用于表示实体属性.
从某种角度上来说, 之前的Memory Networks更像是各种Seq2Seq或Attention Networks的变种, 而Recurrent Entity Networks更加贴近&amp;quot;记忆&amp;quot;这个概念.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-6.png&#34; alt=&#34;Recurrent Entity Networks&#34;&gt;&lt;/p&gt;
&lt;p&gt;下边介绍如何对第$j$个记忆单元进行更新. 注意由于key只用来标识, 真正的记忆内容在value中, 因此只更新value中的内容, key自始至终都不变.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathbf{w}_j$表示第$j$个记忆单元的key&lt;/li&gt;
&lt;li&gt;$\mathbf{h}_j$表示第$j$个记忆单元的value&lt;/li&gt;
&lt;li&gt;$\mathbf{s}_t$表示第$t$条句子&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对第$j$个记忆单元的value值进行更新的步骤为:&lt;/p&gt;
&lt;div&gt;
$$
\begin{array}{l}
g_{j} \leftarrow \sigma\left(\mathbf{s}_{t}^{T} \mathbf{h}_{j}+\mathbf{s}_{t}^{T} \mathbf{w}_{j}\right) \\
\tilde{\mathbf{h}}_{j} \leftarrow \phi\left(\mathbf{U} \mathbf{h}_{j}+\mathbf{V} \mathbf{w}_{j}+\mathbf{W} \mathbf{s}_{t}\right) \\
\mathbf{h}_{j} \leftarrow \mathbf{h}_{j}+g_{j} \odot \tilde{\mathbf{h}_{j}} \\
\mathbf{h}_{j} \leftarrow \frac{\mathbf{h}_{j}}{\left\|\mathbf{h}_{j}\right\|}
\end{array}
$$
&lt;/div&gt;
&lt;h3 id=&#34;gated-end-to-end-memory-networks&#34;&gt;Gated End-to-End Memory Networks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Gated End-to-End Memory Networks (ACL-2017)&lt;/strong&gt; &lt;a href=&#34;https://www.aclweb.org/anthology/E17-1001&#34;&gt;[paper]&lt;/a&gt;
&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-7.png&#34; alt=&#34;Gated End-to-End Memory Networks&#34;&gt;&lt;/p&gt;
&lt;p&gt;此论文的目的只有一个: 通过最少的步骤, 将End-To-End Memory Networks改造为动态记忆网络.
为此, 它将多层记忆之间的传递, 改造成了门控形式.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathbf{u}^k$为第$k$层的输入表示&lt;/li&gt;
&lt;li&gt;$\mathbf{o}^k$为第$k$层记忆单元的注意力加权和&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;改造前:&lt;/p&gt;
&lt;p&gt;$$\mathbf{o}^{k+1} = \mathbf{o}^{k} + \mathbf{u}^{k}$$&lt;/p&gt;
&lt;p&gt;改造后:&lt;/p&gt;
&lt;div&gt;
$$
\begin{aligned}
\mathbf{T}^{k}\left(\mathbf{u}^{k}\right) &amp;=\sigma\left(\mathbf{W}_{T}^{k} \mathbf{u}^{k}+\mathbf{b}_{T}^{k}\right) \\
\mathbf{u}^{k+1} &amp;=\mathbf{o}^{k} \odot \mathbf{T}^{k}\left(\mathbf{u}^{k}\right)+\mathbf{u}^{k} \odot\left(1-\mathbf{T}^{k}\left(\mathbf{u}^{k}\right)\right)
\end{aligned}
$$
&lt;/div&gt;
&lt;h3 id=&#34;working-memory-networks&#34;&gt;Working Memory Networks&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Working Memory Networks: Augmenting Memory Networks with a Relational Reasoning Module (ACL-2018)&lt;/strong&gt; &lt;a href=&#34;https://www.aclweb.org/anthology/P18-1092/&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;还记得上面说到End-To-End Memory Networks中已经有了Transformer的影子.
时间来到2018年, &lt;code&gt;Attention is all you need&lt;/code&gt;已经卷席了整个NLP领域.
这篇文章将multi-head attention引入到Memory Networks中, 同样是在多层记忆处下手.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-03-14-8.png&#34; alt=&#34;Working Memory Networks&#34;&gt;&lt;/p&gt;
&lt;p&gt;与原始的End-To-End Memory Networks中通过QKV计算得到$\mathbf{o}_i$一样, 此处以$f_t(\mathbf{o}_{i-1})$作为Q ($f_t$为MLP层, $\mathbf{o}_{0}=\mathbf{u}$) , 而每个记忆单元都有多头的K和V, 然后完全按照multi-head attention的计算过程, 得到注意力输出$\mathbf{o}_{i}$.&lt;/p&gt;
&lt;p&gt;疑惑的是这里只用到了堆叠的multi-head attention, 却没有skip-connection, 在multi-hops上不会出现梯度消失吗?&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;记忆网络可以分为静态记忆网络(&lt;a href=&#34;https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/#memory-networks&#34;&gt;Memory Networks&lt;/a&gt;, &lt;a href=&#34;https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/#end-to-end-memory-networks&#34;&gt;End-To-End Memory Networks&lt;/a&gt;, &lt;a href=&#34;https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/#key-value-memory-networks&#34;&gt;Key-Value Memory Networks&lt;/a&gt;)和动态记忆网络(&lt;a href=&#34;https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/#dynamic-memory-networks&#34;&gt;Dynamic Memory Networks&lt;/a&gt;, &lt;a href=&#34;https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/#recurrent-entity-networks&#34;&gt;Recurrent Entity Networks&lt;/a&gt;, &lt;a href=&#34;https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/#gated-end-to-end-memory-networks&#34;&gt;Gated End-to-End Memory Networks&lt;/a&gt;, &lt;a href=&#34;https://tmliang.github.io/research/memory-networks-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%A2%B3%E7%90%86/#working-memory-networks&#34;&gt;Working Memory Networks&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;静态记忆网络的记忆单元一旦写入, 就不会进行更新, 改进点主要在于读取部分(如递归读取、注意力加权等).&lt;/p&gt;
&lt;p&gt;而动态记忆网络会随着输入的不同, 记忆单元的内容也会发生改变, 改进点主要在于对记忆单元的更新, 也就是各种门控函数的设计.&lt;/p&gt;
&lt;h3 id=&#34;致谢&#34;&gt;致谢&lt;/h3&gt;
&lt;p&gt;知乎专栏: &lt;a href=&#34;https://www.zhihu.com/column/c_129532277&#34;&gt;记忆网络-Memory Network&lt;/a&gt;&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/">记忆网络</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Exploit Multiple Reference Graphs for Semi-Supervised Relation Extraction</title>
                <link>https://tmliang.github.io/research/exploit-multiple-reference-graphs-for-semi-supervised-relation-extraction/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/exploit-multiple-reference-graphs-for-semi-supervised-relation-extraction/</guid>
                <pubDate>Sat, 13 Mar 2021 12:50:10 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;&lt;strong&gt;Exploit Multiple Reference Graphs for Semi-Supervised Relation Extraction&lt;/strong&gt; &lt;a href=&#34;https://arxiv.org/abs/2010.11383&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文是针对上文的&lt;strong&gt;DualRE&lt;/strong&gt;的改进工作, 加入了一些人工特征信息, 在半监督关系抽取上取得了SOTA的结果, 但遗憾的是缺乏足够的理论分析, 实验也不够充分.&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;DualRE&lt;/strong&gt;使用在有监督样本上预训练的模型对无标签样本进行预测, 要求有监督样本和无监督样本的分布一致.
当两种数据之间的语义鸿沟较大时, &lt;strong&gt;DualRE&lt;/strong&gt;的性能会受到限制.&lt;/p&gt;
&lt;p&gt;为了解决这个问题, 本文通过构造人工特征, 建立起有监督样本和无监督样本之间的联系.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;个人认为这段对DualRE的阐述比较勉强, 而且本文虽然建立起了两种数据之间的联系, 但并没有从根本上解决有/无监督样本之间的语义鸿沟.&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-03-13.png&#34; alt=&#34;模型框架图&#34;&gt;&lt;/p&gt;
&lt;p&gt;模型从下到上可以分为四部分:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Input Module&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;构造三个不同的特征图, 用来连接有监督样本和无监督样本.
这些图都是二分图, 每个节点表示一个句子, 而每条边连接一个有标注句子和一个无标注句子.
三个图中连边的规则如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;实体参考图&lt;/strong&gt;: 如果两个句子包含相同的目标实体, 则连边&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动词参考图&lt;/strong&gt;: 如果两个句子的目标实体对之间的动词相同, 则连边&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;语义参考图&lt;/strong&gt;: 如果两个句子向量的余弦相似度大于阈值, 则连边 (句子向量来自于Prediction Module中的Encoder)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prediction Module&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个Encoder和一个Classifier, 用有监督样本进行训练, 然后对无监督样本进行分类.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Update Module&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将增强后的样本(即得到伪标签的无监督样本)作为有监督的节点, 更新上述三个图, 并且用上一步中更新后的encoder来更新句子向量.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;这里疑惑的是, 增强样本是指从Prediction Module中选出一部分高置信度的无监督样本, 还是上一轮迭代结束后得到的伪标签样本? 如果是前者的话, 是怎么选择的? 如果是后者的话, 在每轮的Input Module中不是已经将这些样本加入有监督集合了么?&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multi GAT Module&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本模块分为三个部分:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用3个GAT分别对3个图进行编码&lt;/li&gt;
&lt;li&gt;通过注意力机制为每个节点计算在三个图上的注意力加权和&lt;/li&gt;
&lt;li&gt;使用Classifier, 对无监督节点进行分类&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终取2和4中的分类结果的交集作为一轮迭代中选取的高置信度样本, 加入到有监督训练集中.&lt;/p&gt;
&lt;h3 id=&#34;experiments&#34;&gt;Experiments&lt;/h3&gt;
&lt;p&gt;在&lt;strong&gt;SemEval&lt;/strong&gt;和&lt;strong&gt;TACRED&lt;/strong&gt;上取得了SOTA的结果.&lt;/p&gt;
&lt;p&gt;消融学习中展示了三个特征图的影响, &lt;strong&gt;动词参考图&lt;/strong&gt; &amp;gt; &lt;strong&gt;实体参考图&lt;/strong&gt; &amp;gt; &lt;strong&gt;语义参考图&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;个人感觉模型还可以进一步精简, 尤其是Prediction Module略显冗余, 这部分是不是必须的? DualRE中两个模块正好互为补充, 而本模型里Prediction Module和MGAT的联系并没有这么紧密. 遗憾的是原文并没有给出该模块的消融分析&lt;/code&gt;&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">关系抽取</category>
                                
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">半监督学习</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Learning Dual Retrieval Module for Semi-Supervised Relation Extraction</title>
                <link>https://tmliang.github.io/research/learning-dual-retrieval-module-for-semi-supervised-relation-extraction/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/learning-dual-retrieval-module-for-semi-supervised-relation-extraction/</guid>
                <pubDate>Fri, 12 Mar 2021 20:34:50 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;&lt;strong&gt;Learning Dual Retrieval Module for Semi-Supervised Relation Extraction (WWW-2019)&lt;/strong&gt; &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3308558.3313573&#34;&gt;[paper]&lt;/a&gt; &lt;a href=&#34;https://github.com/INK-USC/DualRE&#34;&gt;[code]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文将&lt;strong&gt;关系抽取&lt;/strong&gt;和&lt;strong&gt;句子检索&lt;/strong&gt;视为对偶问题, 通过两者的相互迭代促进, 弥补了self-ensemble和self-training的不足, 在半监督关系抽取上的表现有了明显的提升.
本文行文流畅、创新性强、推导合理、实验充分, 绝对是近年来关系抽取领域中的一篇佳作.&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;常见的半监督关系抽取方法有两种&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;self-ensembling method&lt;/strong&gt;: 多个模型对无监督样本进行预测, 当大多数模型给出相同的判断时, 为该样本分配该标签&lt;/p&gt;
&lt;p&gt;该方法的缺点是不能迭代地增加训练样本, 而少量的有标签样本不足以训练多个模型.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;self-training method&lt;/strong&gt;: 在每步迭代中, 找出高置信度的样本加入训练集中, 然后用扩大后的训练集继续训练模型&lt;/p&gt;
&lt;p&gt;该方法的缺点是随着伪标签样本的不断加入, 会逐渐发生语义漂移.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文将&lt;strong&gt;关系抽取&lt;/strong&gt;和&lt;strong&gt;句子检索&lt;/strong&gt;视为对偶问题. 前者是输入句子, 输出关系标签; 后者是输入关系标签, 输出按照与该标签的相关性排序的句子列表.
本文提出的方法可以看作以上两者的相互融合和相互弥补, 使用一个关系抽取模型和一个检索模型来投票表决, 并将选中样本的交集加入到下一轮的训练.&lt;/p&gt;
&lt;h3 id=&#34;method&#34;&gt;Method&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2021-03-12.png&#34; alt=&#34;模型框架图&#34;&gt;&lt;/p&gt;
&lt;p&gt;本框架通过EM算法对两个模型进行迭代更新.&lt;/p&gt;
&lt;p&gt;首先使用有标签训练集$L$对关系抽取模型$P_\theta$和检索模型$Q_\phi$进行预训练, 然后迭代进行以下EM步骤:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;挑选样本&lt;/strong&gt;: 使用$P_\theta$和$Q_\phi$分别选出高置信度的无标签样本, 然后取其交集$L&#39;$. 将$L&#39;$从无标签集合$U$中移除, 并加入到训练集$L$中&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;E步&lt;/strong&gt;: 使用$L$训练$P_\theta$, 定义损失为cross entropy&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;M步&lt;/strong&gt;: 使用$L$训练$Q_\phi$, 定义损失为排序学习中的point-wise loss (最大化正例分数, 最小化负例分数)和pair-wise loss (最大化正负例之间的差距)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;details&#34;&gt;Details&lt;/h3&gt;
&lt;p&gt;虽然算法过程看似简单, 但作者进行了非常有意思的分析和推导. 这些细节也是这篇文章的主要亮点.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;样本的选择&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;在最初的想法中, 作者是想只用检索模型来挑选样本, 但是这样挑选的样本是有偏的.&lt;/p&gt;
&lt;div&gt;
$$\mathbb{E}_{p_{\theta}(y \mid x)}\left[\nabla_{\theta} \log p_{\theta}(y \mid x)\right]=\mathbb{E}_{p_{\theta}(y \mid x)}\left[\frac{\nabla_{\theta} p_{\theta}(y \mid x)}{p_{\theta}(y \mid x)}\right]=\sum \nabla_{\theta} p_{\theta}(y \mid x)=\nabla_{\theta} \sum p_{\theta}(y \mid x)=\nabla_{\theta} 1=0
$$
&lt;/div&gt;
&lt;p&gt;由以上推导可得, $\mathbb{E}_{p_{\theta}(y \mid x)}\left[\nabla_{\theta} \log p_{\theta}(y \mid x)\right]$和$\mathbb{E}_{q_{\phi}(x \mid y)}\left[\nabla_{\phi} \log q_{\phi}(x \mid y)\right]$都是$0$. 因此, $\mathbb{E}_{x \in U, y \sim q_{\phi}(y \mid x)}\left[\nabla_{\theta} \log p_{\theta}(y \mid x)\right]=\mathbb{E}_{x \in U, y \sim (q_{\phi}(y \mid x) + p_\theta(y \mid x))}\left[\nabla_{\theta} \log p_{\theta}(y \mid x)\right]$. 即, 只用检索模型挑选样本和两个模型一起用, 优化目标是相同的.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;样本权重&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;考虑到伪标签样本和真实标签样本混合的话, 其中的错误标签可能会误导模型, 因此为伪标签样本设置样本权重.
关系抽取模型和检索模型所挑选样本的权重分别为$p_\theta(y\mid x)^\alpha$和$q_\phi(x\mid y)^\beta$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本模块分为三个部分:&lt;/p&gt;
&lt;h3 id=&#34;experiments&#34;&gt;Experiments&lt;/h3&gt;
&lt;p&gt;作者在&lt;strong&gt;SemEval&lt;/strong&gt;和&lt;strong&gt;TACRED&lt;/strong&gt;上进行了多组实验, 实验结果分析如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;编码器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;测试了LSTM、PCNN和PRNN三种编码器, 其中PRNN性能最佳, 因此以PRNN作为后续实验的编码器.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;半监督方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;测试了Mean-Teacher (Self-Ensemble)、Self-Training和RE-Ensemble (把本框架中的检索模型替换成关系抽取模型, 即两个关系抽取模型的集成方法)三种半监督的Baselines, 结果一致表明: 本方法 &amp;gt; RE-Ensemble &amp;gt; Self-Training &amp;gt; Mean-Teacher.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;排序损失&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;测试了Point-Wise和Pair-Wise两种检索模型的性能, Point-Wise的结果稍好.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有标签数据集越大越好, 无标签数据集不一定越大越好.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;样本权重&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$\alpha=0.5$, $\beta=2$时表现最好, $\alpha=0$, $\beta=0$ (即不设置样本权重)时最差.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;关系选择&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用检索模型挑选样本时, 如何选择哪些关系进行输入?
一种方式是直接使用训练集$L$中的关系分布进行采样.
另一种方式是在关系抽取模型所挑选的高置信度样本中, 选择置信度最高的$n$种关系.&lt;/p&gt;
&lt;p&gt;实验表明$n=3$时最好.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;挑选样本的质量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;测试了每轮迭代后模型的表现, 发现随着伪标签样本的加入, Precision不断下降, 而F1-Scores不断上升, 说明了所挑选的样本虽然会带来准确率的下降, 但是召回上升更快, 其质量还是过关的.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">关系抽取</category>
                                
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">半监督学习</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>An Improved Baseline for Sentence-level Relation Extraction</title>
                <link>https://tmliang.github.io/research/an-improved-baseline-for-sentence-level-relation-extraction/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/an-improved-baseline-for-sentence-level-relation-extraction/</guid>
                <pubDate>Wed, 10 Mar 2021 13:07:52 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;&lt;strong&gt;An Improved Baseline for Sentence-level Relation Extraction (Arxiv-2021)&lt;/strong&gt; &lt;a href=&#34;https://arxiv.org/abs/2102.01373&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文聚焦于当前关系抽取实践中两个非常重要却经常被忽视的部分: &lt;strong&gt;实体的表示方式&lt;/strong&gt;和&lt;strong&gt;NA类的处理&lt;/strong&gt;. 通篇语言流畅, 而且叙述结构非常清晰, 个人认为是今年最好的一篇关系抽取文章.&lt;/p&gt;
&lt;h3 id=&#34;entity-representation&#34;&gt;Entity Representation&lt;/h3&gt;
&lt;p&gt;替换实体对的方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Entity Mask&lt;/strong&gt;: [SUBJ-类型名], [OBJ-类型名]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Entity Marker&lt;/strong&gt;: [E1]头实体[/E1], [E2]尾实体[/E2]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Entity Marker(punct)&lt;/strong&gt;: @头实体@, #尾实体#&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type Entity Marker&lt;/strong&gt;: [E1-类型名]头实体[/E1-类型名], [E2-类型名]尾实体[/E2-类型名]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type Entity Marker(punct)&lt;/strong&gt;: @*类型名*头实体@, #^类型名^尾实体#&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验表明后两种表现最好.&lt;/p&gt;
&lt;p&gt;下面是作者关于训练时是否应该掩盖实体名的分析:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有人认为训练时不掩盖实体名, 会导致测试集的标签泄漏, 而且无法扩展到新实体. 但我认为, 实体名提供了重要的实体信息, 而且, 如果实体名不能使用, 那么那些基于外部三元组知识的方法也不该使用, 因为他们同样泄露了目标实体的信息.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了证实自己的观点, 作者将测试集中包含训练实体的句子过滤掉, 最终结果表明, 非mask的仍然优于mask.&lt;/p&gt;
&lt;h3 id=&#34;confidence-based-classification&#34;&gt;Confidence-based Classification&lt;/h3&gt;
&lt;p&gt;作者认为, 不应该将NA视作关系分类中的一个独立类别, 因为NA中包含着无数种不同语义的实例, 很难由一个类别建模.&lt;/p&gt;
&lt;p&gt;本方法设立阈值进行分类, 若预测分数低于阈值, 则被视作NA. 类似于Openset Classification和Out-of-distribution Detection.&lt;/p&gt;
&lt;p&gt;Loss的设计:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NA类具有极低的置信度&lt;/li&gt;
&lt;li&gt;正关系具有极高的置信度&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2可以通过Cross Entropy实现. 但对于1, 直接降低置信度是很难优化的, 因为最大预测概率所对应的关系也会被更新, 因此, 提出了最小化NA类的置信度代理:&lt;/p&gt;
&lt;div&gt;
$$\begin{aligned}
    c_{\text {sup }} &amp;=\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2} \\
    \mathcal{L}_{\text {conf }} &amp;=\log \left(1-c_{\text {sup }}\right)
\end{aligned}$$
&lt;/div&gt;
&lt;p&gt;由计算可知, 置信度$c=\max_{r\in R}p_{r}\leq C_{\text{sup }}$, 最小化$\mathcal{L}_{\text {conf }}$相当于最小化$c$, 使得训练更稳定.&lt;/p&gt;
&lt;p&gt;对关系$r$的logit值$l_r$求导:&lt;/p&gt;
&lt;div&gt;
$$\frac{\partial \mathcal{L}_{\mathrm{conf}}}{l_{r}}=-\frac{2 \boldsymbol{p}_{r}\left(\boldsymbol{p}_{r}-\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2}\right)}{1-\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2}}$$
&lt;/div&gt;
&lt;p&gt;由此可知:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当$\boldsymbol{p}_{r}=\frac{1}{\mid \mathcal{R}]}$, $\forall r \in \mathcal{R}$, $\mathcal{L}_{\text {conf }}$最小, 即此时各关系为均匀分布.&lt;/li&gt;
&lt;li&gt;训练实例的$\mathcal{L}_{\text {conf }}$惩罚为$\frac{1}{1-\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2}}$, 因此置信度高的实例会受到更多惩罚.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终, 结合&lt;strong&gt;Type Entity Marker(punct)&lt;strong&gt;和&lt;/strong&gt;Confidence-based Classification&lt;/strong&gt;的方法在TACRED和SemEval 2010 Task 8上都取得了SOTA结果.&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">关系抽取</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Effective Deep Memory Networks for Distant Supervised Relation Extraction</title>
                <link>https://tmliang.github.io/research/effective-deep-memory-networks-for-distant-supervised-relation-extraction/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/effective-deep-memory-networks-for-distant-supervised-relation-extraction/</guid>
                <pubDate>Wed, 11 Mar 2020 22:39:40 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;&lt;strong&gt;Effective Deep Memory Networks for Distant Supervised Relation Extraction (IJCAI-2017)&lt;/strong&gt; &lt;a href=&#34;https://www.ijcai.org/Proceedings/2017/0559.pdf&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文的出发点很好, 考虑到了句子中不同词的重要性和关系标签之间的依赖两点. 但是就模型架构而言, 与其说是Memory Networks, 不如说更像是多层的注意力网络. 考虑到文章发表时Transformers还没有大行其道 (虽然注意力机制已经非常流行), 本文还是比较有创新性的.&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;句子中不同的词对于目标实体对的重要性是不同的&lt;/li&gt;
&lt;li&gt;不同关系之间的依赖(如包含, 冲突等), 对于某些隐式关系的推断很有帮助&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;method&#34;&gt;Method&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tmliang.github.io/images/2020-03-11.png&#34; alt=&#34;模型框架图&#34;&gt;&lt;/p&gt;
&lt;p&gt;模型主要分为三块:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;词级别&lt;/p&gt;
&lt;p&gt;在左下角模块里, 使用多层注意力模块来融合上下文信息, 即&lt;strong&gt;Motivation 1&lt;/strong&gt;.
在第一层里, 以实体对作为输入, 然后计算&lt;strong&gt;每个词&lt;/strong&gt;对&lt;strong&gt;该实体对&lt;/strong&gt;的注意力加权和, 作为该层的输出.
此后每层均以上一层的输出作为输入, 然后输出该层中上下文单词的注意力加权和.&lt;/p&gt;
&lt;p&gt;最终, 将注意力模块的输出与CNN编码的句子向量拼接, 构成了本模型的句子向量.&lt;/p&gt;
&lt;p&gt;文中4.4实验部分表明, 层数为6时模型表现最佳.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;句子级别&lt;/p&gt;
&lt;p&gt;在右下角模块里, 包含了两层不同的注意力模块.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在第一层中, 计算&lt;strong&gt;每条句子&lt;/strong&gt;对&lt;strong&gt;该关系&lt;/strong&gt;的注意力加权和, 作为该层的输出. 即DSRE里最常见的Selective Attention.&lt;/li&gt;
&lt;li&gt;在第二层中, 计算&lt;strong&gt;其他关系&lt;/strong&gt;对&lt;strong&gt;该关系&lt;/strong&gt;的注意力加权和, 可看作关系之间的自注意力,即&lt;strong&gt;Motivation 2&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终为每个关系输出一个向量表示.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分类器&lt;/p&gt;
&lt;p&gt;由于是multi-label classification, 因此分别对每个关系向量进行sigmoid分类.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;experiment&#34;&gt;Experiment&lt;/h3&gt;
&lt;p&gt;实验在过滤版NYT数据集上进行, 结果没有想象中好, 只比PCNN+ATT好了一丢丢, 但是模型复杂度却要高很多. 虽然Motivation很好, 但是这种简单的注意力模块并没有把Motivation完全挖掘出来. 个人感觉这个Motivation, 包括Memory Networks和关系依赖, 都还有很大的挖掘空间.&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">关系抽取</category>
                                
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3/">远程监督</category>
                                
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/">记忆网络</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>基于远程监督的关系抽取研究现状</title>
                <link>https://tmliang.github.io/research/%E5%9F%BA%E4%BA%8E%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3%E7%9A%84%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/%E5%9F%BA%E4%BA%8E%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3%E7%9A%84%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6/</guid>
                <pubDate>Sun, 09 Feb 2020 18:25:58 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;关系抽取建立在命名实体识别的基础上，是知识图谱补全的重要任务之一。关系抽取的目标是从文本中提取出两个实体之间的语义关系。传统的关系抽取虽然已经达到相当好的效果，但需要人工预先精准地标注大量句子级别的数据，标注成本十分昂贵。在实际场景中，面向数以千计的关系、数以千万计的实体对、以及数以亿计的句子，依靠人工标注训练数据几乎是不可能完成的任务&lt;sup&gt;[1]&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;为了获得大量的机器标注的训练数据，Mintz M&lt;sup&gt;[2]&lt;/sup&gt;等人将远程监督的概念应用到关系抽取任务中，并提出一个非常著名的假设：两个实体如果在知识库中存在某种关系，则包含该两个实体的所有句子都在以某种方式表达这种关系。远程监督能够显著减少关系抽取任务所需的标注成本，但其过强的假设为数据引入了大量噪声。自2009年远程监督的假设提出之后，便有大量的学者投身于此研究中，致力于降低远程监督所带来的标签噪声。&lt;/p&gt;
&lt;p&gt;远程监督的第一个重大进展是多实例学习的引入。Zeng&lt;sup&gt;[3]&lt;/sup&gt;等人弱化了远程监督的假设：两个实体如果在知识库中存在某种关系，则包含该两个实体的所有句子中，至少有一句在表达这个关系。他们将包含同一对实体的所有句子构成一个包，然后使用PCNN模型提取每个句子的表征，最后以包中概率最大的句子表征作为这个包的表征，通过Softmax进行分类。Lin&lt;sup&gt;[4]&lt;/sup&gt;等人则认为只使用包中最大概率的句子进行分类，会丢弃掉包中其他句子的有效信息，于是他们引入了句子级别的注意力，为包中每个句子赋予一个注意力权重，然后以包中所有句子表征的加权和作为这个包的表征。Lin等人的方法能够非常有效地降低远程监督所带来的标签噪声，现已成为基于远程监督的关系抽取中常用的Baseline了，许多学者在此基础上深入研究。&lt;/p&gt;
&lt;p&gt;另一种降低标签噪声影响的思路是提高模型的抗噪能力。Wu&lt;sup&gt;[5]&lt;/sup&gt;等人引入了对抗训练，以此增强模型对噪声数据的抵抗能力。&lt;/p&gt;
&lt;p&gt;虽然多实例学习和对抗训练可以降低标签噪声的影响，但并不能从根本上消除噪声。Feng&lt;sup&gt;[6]&lt;/sup&gt;等人借助强化学习模型，直接过滤掉训练样本中的噪声句子，然后使用剩下的训练数据来训练模型。Qin&lt;sup&gt;[7]&lt;/sup&gt;等人使用了生成对抗网络。他们使用生成器来划分数据，使用判别器来评价该划分的好坏，通过生成器和判别器的相互促进，最终得到一个能从训练集中筛选出噪声句子的生成器。&lt;/p&gt;
&lt;p&gt;上述工作虽然都在一定程度上降低了远程监督所带来的噪声影响，但仍局限于语料集本身，可用的信息只有文本统计的数据。近年来许多学者开始尝试借助外部知识的指导，进一步提高关系抽取模型的能力。Lei&lt;sup&gt;[8]&lt;/sup&gt;等人提出了协同降噪框架，利用知识图谱中的监督信息来降低远程监督的标签噪声。该框架使用两个神经网络分别在文本和知识图谱上学习，然后通过双向知识蒸馏模块完成它们之间的共同学习。Vashishth&lt;sup&gt;[9]&lt;/sup&gt;等人使用关系别名和实体类型这两种知识库信息来丰富了文本中的关系和实体信息。Xu&lt;sup&gt;[10]&lt;/sup&gt;等人通过知识图谱嵌入和关系抽取的联合学习，显著地提高了在远程监督下的关系抽取性能。&lt;/p&gt;
&lt;p&gt;除了借助外部知识的指导，还有学者在研究如何借助有监督下的关系抽取模型来指导远程监督下的关系抽取。然而现有的有监督数据集和远程监督数据集中的关系标签通常是不重合的，如何结合两种数据以提高远程监督下的关系抽取性能，是这个方向的首要任务。大多数的结合方法都是把两个数据集简单的混到一起，然后增加分类的类别。Beltagy&lt;sup&gt;[11]&lt;/sup&gt;等人则提出了更有效的结合方法，他们在有监督数据集上训练了一个二元关系分类器，判断句子是否表达了两个实体之间的关系，然后用此分类器来滤除远程监督样本中的假阳性噪声数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]   韩旭, 高天宇, 刘知远, et al. 知识图谱从哪里来：实体关系抽取的现状与未来[EB/OL]. 2019-11-7[2020-1-9]. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/91762831&#34;&gt;https://zhuanlan.zhihu.com/p/91762831&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[2]   Mintz M, Bills S, Snow R, et al. Distant supervision for relation extraction without labeled data[C]//Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009: 1003-1011.&lt;/p&gt;
&lt;p&gt;[3]   Zeng D, Liu K, Chen Y, et al. Distant supervision for relation extraction via piecewise convolutional neural networks[C]//Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015: 1753-1762.&lt;/p&gt;
&lt;p&gt;[4]   Lin Y, Shen S, Liu Z, et al. Neural relation extraction with selective attention over instances[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2016: 2124-2133.&lt;/p&gt;
&lt;p&gt;[5]   Wu Y, Bamman D, Russell S. Adversarial training for relation extraction[C]//Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017: 1778-1783.&lt;/p&gt;
&lt;p&gt;[6]   Feng J, Huang M, Zhao L, et al. Reinforcement learning for relation classification from noisy data[C]//Thirty-Second AAAI Conference on Artificial Intelligence. 2018.&lt;/p&gt;
&lt;p&gt;[7]   Qin P, Weiran X U, Wang W Y. DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction[C]//Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018, 1: 496-505.&lt;/p&gt;
&lt;p&gt;[8]   Lei K, Chen D, Li Y, et al. Cooperative denoising for distantly supervised relation extraction[C]//Proceedings of the 27th International Conference on Computational Linguistics. 2018: 426-436.&lt;/p&gt;
&lt;p&gt;[9]   Vashishth S, Joshi R, Prayaga S S, et al. RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information[C]//Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018: 1257-1266.&lt;/p&gt;
&lt;p&gt;[10]  Xu P, Barbosa D. Connecting Language and Knowledge with Heterogeneous Representations for Neural Relation Extraction[C]//Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019: 3201-3206.&lt;/p&gt;
&lt;p&gt;[11]Beltagy I, Lo K, Ammar W. Combining distant and direct supervision for neural relation extraction[C]//Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019: 1858-1867.&lt;/p&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/">关系抽取</category>
                                
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3/">远程监督</category>
                                
                            
                        
                    
                
            </item>
        
            <item>
                <title>Text-Enhanced Representation Learning for Knowledge Graph</title>
                <link>https://tmliang.github.io/research/text-enhanced-representation-learning-for-knowledge-graph/</link>
                <guid isPermaLink="true">https://tmliang.github.io/research/text-enhanced-representation-learning-for-knowledge-graph/</guid>
                <pubDate>Wed, 18 Sep 2019 18:14:51 &#43;0800</pubDate>
                
                    <author>tm.liang@outlook.com (Liang Tianming)</author>
                
                <copyright>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</copyright>
                
                    <description>&lt;p&gt;&lt;strong&gt;Text-Enhanced Representation Learning for Knowledge Graph (IJCAI-2016)&lt;/strong&gt; &lt;a href=&#34;https://www.ijcai.org/Proceedings/16/Papers/187.pdf&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;TransE、TransH、TransR&lt;/em&gt; 在 &lt;em&gt;1-N, N-1&lt;/em&gt; 和 &lt;em&gt;N-N&lt;/em&gt; 关系中的表现不佳&lt;/li&gt;
&lt;li&gt;图谱结构稀疏导致学习到的表征不准确&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;利用Word2Vec从文本中学习实体和关系的上下文表征, 然后线性变换到图谱嵌入空间中.学习线性变换的参数, 使得图谱嵌入空间中, 正确三元组的$|\widehat{\mathbf{h}}+\widehat{\mathbf{r}}-\widehat{\mathbf{t}}|_{2}^{2}$ 接近于0.&lt;/p&gt;
&lt;h3 id=&#34;input&#34;&gt;Input&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;知识图谱 $KG$, 以三元组$(h,r,t)$表示&lt;/li&gt;
&lt;li&gt;语料库 $D=\left\{w_{1}, w_{2}, \cdots, w_{m}\right\}$, $w_{i}$为单词, $m$为文本长度&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;method&#34;&gt;Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h5 id=&#34;entity-annotation&#34;&gt;Entity Annotation&lt;/h5&gt;
&lt;p&gt;使用实体链接工具(AIDA, TAGME, Wikify! 等)来标注$D$中的实体. 标注后得到 ${\rm{D&#39;}}=\left\{x_{1}, x_{2}, \cdots, x_{m}\right\}$, $x_{i}$为$KG$中的实体或$D$中的单词. 其中$m&#39;&amp;lt;m$, 因为$D$中的一些词组(连续几个单词)被标为了一个实体.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;textual-context-embedding&#34;&gt;Textual Context Embedding&lt;/h5&gt;
&lt;p&gt;构建共现网络 $\mathcal{G}=(\mathcal{X}, \mathcal{Y})$ , 其中$x_{i} \in \mathcal{X}$表示单词或实体, $y_{ij} \in \mathcal{Y}$ 表示$x_{i}$和$y_{i}$的共现频率, 共现窗口设置为5.&lt;/p&gt;
&lt;p&gt;按下述步骤计算:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;pointwise textual context:&lt;/strong&gt;&lt;/p&gt;
&lt;div&gt; 
$$n\left(x_{i}\right)=\left\{x_{j} | y_{i j}&gt;\theta\right\}$$
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;pairtwise textual context:&lt;/strong&gt;&lt;/p&gt;
&lt;div&gt; 
$$n\left(x_{i}, x_{j}\right)=\left\{x_{k} | x_{k} \in n\left(x_{i}\right) \cap n\left(x_{j}\right)\right\}$$
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;pointwise textual context embedding:&lt;/strong&gt;
$$\mathbf{n}\left(x_{i}\right)=\frac{1}{\sum_{x_{j} \in n\left(x_{i}\right)} y_{i j}} \sum_{x_{j} \in n\left(x_{i}\right)} y_{i j} \mathbf{x}_{j}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;pairwise textual context embedding:&lt;/strong&gt;&lt;br&gt;
$${\bf{n}}\left( {{x_i},{x_j}} \right) = {1 \over {\sum\limits_{{x_k} \in n\left( {{x_i},{x_j}} \right)} {\min } \left( {{y_{ik}},{y_{jk}}} \right)}}\sum\limits_{{x_k} \in n\left( {{x_i},{x_j}} \right)} {\min } \left( {{y_{ik}},{y_{jk}}} \right){{\bf{x}}_k}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;entityrelation-representation-modeling-算法核心&#34;&gt;Entity/Relation Representation Modeling (算法核心)&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;$h$的点嵌入的线性变换&lt;/strong&gt;
$$\widehat{\mathbf{h}}=\mathbf{n}(h) \mathbf{A}+\mathbf{h}$$
&lt;strong&gt;$t$的点嵌入的线性变换&lt;/strong&gt;
$$\widehat{\mathbf{t}}=\mathbf{n}(t) \mathbf{A}+\mathbf{t}$$
&lt;strong&gt;$r$的对嵌入的线性变换&lt;/strong&gt;
$$\widehat{\mathbf{r}}=\mathbf{n}(h,t) \mathbf{B}+\mathbf{r}$$
其中A, B为权重矩阵, h,t和r是偏差.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score Fuction&lt;/strong&gt;
$$f(h, r, t)=|\widehat{\mathbf{h}}+\widehat{\mathbf{r}}-\widehat{\mathbf{t}}|_{2}^{2}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;representation-traning&#34;&gt;Representation Traning&lt;/h5&gt;
&lt;p&gt;优化目标
$$L=\sum_{(h, r, t) \in \mathcal{S}\left(h^{\prime}, r, t^{\prime}\right) \in \mathcal{S}^{\prime}} \max \left(0, f(h, r, t)+\gamma-f\left(h^{\prime}, r, t^{\prime}\right)\right)$$
其中$f(h, r, t)$表示正样本,  $f\left(h^{\prime}, r, t^{\prime}\right)$表示负样本.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-question&#34;&gt;4. Question&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;为什么能解决图谱的稀疏性问题?
&lt;ul&gt;
&lt;li&gt;利用Word2Vec从文本中学习表征, 而不是从稀疏的图谱中学习表征.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;为什么能更好处理 &lt;em&gt;1-N&lt;/em&gt;, &lt;em&gt;N-1&lt;/em&gt; 和 &lt;em&gt;N-N&lt;/em&gt; 关系?
&lt;ul&gt;
&lt;li&gt;例如在 $\widehat{\mathbf{h}}=\mathbf{n}(h) \mathbf{A}+\mathbf{h}$ 中, 对于不同的头实体, $\mathbf{A}$和$\mathbf{h}$是共享的, 因此只要$\mathbf{n}(h)$不同, $\widehat{\mathbf{h}}$ 就不会相同.&lt;/li&gt;
&lt;li&gt;当$t$固定时, 即使关系相同, 对于不同的$h$, 对嵌入$\mathbf{n}(h,t)$也不尽相同, 也就是说同一个关系会有多个表征.&lt;/li&gt;
&lt;li&gt;由以上两点可知, 在训练时, $\widehat{\mathbf{r}}$ 会不断改变, 因此不会出现TransE中相同的关系下不同头(尾)实体的表示近似相等的情况.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;同样的关系有不同的表示, 那么要使用某个关系的时候要用哪个表示?&lt;/li&gt;
&lt;li&gt;在 &lt;em&gt;1-1&lt;/em&gt; 关系上的性能不如 &lt;em&gt;TransH&lt;/em&gt; 和 &lt;em&gt;TransR&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                
                
                
                
                
                    
                        
                    
                        
                            
                                
                                
                                
                                    <category domain="https://tmliang.github.io/tags/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA/">知识表示</category>
                                
                            
                        
                    
                
            </item>
        
    </channel>
</rss>
