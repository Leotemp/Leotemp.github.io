<?xml version="1.0" encoding="utf-8"?>


<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-CN">
    <title type="text">九月</title>
    <subtitle type="html">记录我的科研生活</subtitle>
    <updated>2021-03-10T17:36:16&#43;08:00</updated>
    <id>https://tmliang.github.io/</id>
    <link rel="alternate" type="text/html" href="https://tmliang.github.io/" />
    <link rel="self" type="application/atom&#43;xml" href="https://tmliang.github.io/atom.xml" />
    <author>
            <name>Liang Tianming</name>
            <uri>https://tmliang.github.io/</uri>
            
                <email>tm.liang@outlook.com</email>
            </author>
    <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</rights>
    <generator uri="https://gohugo.io/" version="0.81.0">Hugo</generator>
        <entry>
            <title type="text">An Improved Baseline for Sentence-level Relation Extraction</title>
            <link rel="alternate" type="text/html" href="https://tmliang.github.io/research/an-improved-baseline-for-sentence-level-relation-extraction/" />
            <id>https://tmliang.github.io/research/an-improved-baseline-for-sentence-level-relation-extraction/</id>
            <updated>2021-03-10T17:36:03&#43;08:00</updated>
            <published>2021-03-10T13:07:52&#43;08:00</published>
            <author>
                    <name>Liang Tianming</name>
                    <uri>https://tmliang.github.io</uri>
                    <email>tm.liang@outlook.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</rights><summary type="html">An Improved Baseline for Sentence-level Relation Extraction (Arxiv-2021) [paper] 本文聚焦于当前关系抽取实践中两个非常重要却经常被忽视的部分: 实体的……</summary>
            
                <content type="html">&lt;p&gt;&lt;strong&gt;An Improved Baseline for Sentence-level Relation Extraction (Arxiv-2021)&lt;/strong&gt; &lt;a href=&#34;https://arxiv.org/abs/2102.01373&#34;&gt;[paper]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文聚焦于当前关系抽取实践中两个非常重要却经常被忽视的部分: &lt;strong&gt;实体的表示方式&lt;/strong&gt;和&lt;strong&gt;NA类的处理&lt;/strong&gt;. 通篇语言流畅, 而且叙述结构非常清晰, 个人认为是今年最好的一篇关系抽取文章.&lt;/p&gt;
&lt;h3 id=&#34;entity-representation&#34;&gt;Entity Representation&lt;/h3&gt;
&lt;p&gt;替换实体对的方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Entity Mask&lt;/strong&gt;: [SUBJ-类型名], [OBJ-类型名]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Entity Marker&lt;/strong&gt;: [E1]头实体[/E1], [E2]尾实体[/E2]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Entity Marker(punct)&lt;/strong&gt;: @头实体@, #尾实体#&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type Entity Marker&lt;/strong&gt;: [E1-类型名]头实体[/E1-类型名], [E2-类型名]尾实体[/E2-类型名]&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type Entity Marker(punct)&lt;/strong&gt;: @*类型名*头实体@, #^类型名^尾实体#&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验表明后两种表现最好.&lt;/p&gt;
&lt;p&gt;下面是作者关于训练时是否应该掩盖实体名的分析:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有人认为训练时不掩盖实体名, 会导致测试集的标签泄漏, 而且无法扩展到新实体. 但我认为, 实体名提供了重要的实体信息, 而且, 如果实体名不能使用, 那么那些基于外部三元组知识的方法也不该使用, 因为他们同样泄露了目标实体的信息.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了证实自己的观点, 作者将测试集中包含训练实体的句子过滤掉, 最终结果表明, 非mask的仍然优于mask.&lt;/p&gt;
&lt;h3 id=&#34;confidence-based-classification&#34;&gt;Confidence-based Classification&lt;/h3&gt;
&lt;p&gt;作者认为, 不应该将NA视作关系分类中的一个独立类别, 因为NA中包含着无数种不同语义的实例, 很难由一个类别建模.&lt;/p&gt;
&lt;p&gt;本方法设立阈值进行分类, 若预测分数低于阈值, 则被视作NA. 类似于Openset Classification和Out-of-distribution Detection.&lt;/p&gt;
&lt;p&gt;Loss的设计:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NA类具有极低的置信度&lt;/li&gt;
&lt;li&gt;正关系具有极高的置信度&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;2可以通过Cross Entropy实现. 但对于1, 直接降低置信度是很难优化的, 因为最大预测概率所对应的关系也会被更新, 因此, 提出了最小化NA类的置信度代理:&lt;/p&gt;
&lt;div&gt;
$$\begin{aligned}
    c_{\text {sup }} &amp;=\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2} \\
    \mathcal{L}_{\text {conf }} &amp;=\log \left(1-c_{\text {sup }}\right)
\end{aligned}$$
&lt;/div&gt;
&lt;p&gt;由计算可知, 置信度$c=\max_{r\in R}p_{r}\leq C_{\text{sup }}$, 最小化$\mathcal{L}_{\text {conf }}$相当于最小化$c$, 使得训练更稳定.&lt;/p&gt;
&lt;p&gt;对关系$r$的logit值$l_r$求导:&lt;/p&gt;
&lt;div&gt;
$$\frac{\partial \mathcal{L}_{\mathrm{conf}}}{l_{r}}=-\frac{2 \boldsymbol{p}_{r}\left(\boldsymbol{p}_{r}-\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2}\right)}{1-\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2}}$$
&lt;/div&gt;
&lt;p&gt;由此可知:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当$\boldsymbol{p}_{r}=\frac{1}{\mid \mathcal{R}]}$, $\forall r \in \mathcal{R}$, $\mathcal{L}_{\text {conf }}$最小, 即此时各关系为均匀分布.&lt;/li&gt;
&lt;li&gt;训练实例的$\mathcal{L}_{\text {conf }}$惩罚为$\frac{1}{1-\sum_{r \in \mathcal{R}} \boldsymbol{p}_{r}^{2}}$, 因此置信度高的实例会受到更多惩罚.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终, 结合&lt;strong&gt;Type Entity Marker(punct)&lt;strong&gt;和&lt;/strong&gt;Confidence-based Classification&lt;/strong&gt;的方法在TACRED和SemEval 2010 Task 8上都取得了SOTA结果.&lt;/p&gt;
</content>
            
            
            
            
            
                
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://tmliang.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/" term="关系抽取" label="关系抽取" />
                            
                        
                    
                
            
        </entry>
    
        <entry>
            <title type="text">基于远程监督的关系抽取研究现状</title>
            <link rel="alternate" type="text/html" href="https://tmliang.github.io/research/%E5%9F%BA%E4%BA%8E%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3%E7%9A%84%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6/" />
            <id>https://tmliang.github.io/research/%E5%9F%BA%E4%BA%8E%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3%E7%9A%84%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6/</id>
            <updated>2021-03-10T17:31:26&#43;08:00</updated>
            <published>2020-02-09T18:25:58&#43;00:00</published>
            <author>
                    <name>Liang Tianming</name>
                    <uri>https://tmliang.github.io</uri>
                    <email>tm.liang@outlook.com</email>
                    </author>
            <rights>[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)</rights><summary type="html">关系抽取建立在命名实体识别的基础上，是知识图谱补全的重要任务之一。关系抽取的目标是从……</summary>
            
                <content type="html">&lt;p&gt;关系抽取建立在命名实体识别的基础上，是知识图谱补全的重要任务之一。关系抽取的目标是从文本中提取出两个实体之间的语义关系。传统的关系抽取虽然已经达到相当好的效果，但需要人工预先精准地标注大量句子级别的数据，标注成本十分昂贵。在实际场景中，面向数以千计的关系、数以千万计的实体对、以及数以亿计的句子，依靠人工标注训练数据几乎是不可能完成的任务&lt;sup&gt;[1]&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;为了获得大量的机器标注的训练数据，Mintz M&lt;sup&gt;[2]&lt;/sup&gt;等人将远程监督的概念应用到关系抽取任务中，并提出一个非常著名的假设：两个实体如果在知识库中存在某种关系，则包含该两个实体的所有句子都在以某种方式表达这种关系。远程监督能够显著减少关系抽取任务所需的标注成本，但其过强的假设为数据引入了大量噪声。自2009年远程监督的假设提出之后，便有大量的学者投身于此研究中，致力于降低远程监督所带来的标签噪声。&lt;/p&gt;
&lt;p&gt;远程监督的第一个重大进展是多实例学习的引入。Zeng&lt;sup&gt;[3]&lt;/sup&gt;等人弱化了远程监督的假设：两个实体如果在知识库中存在某种关系，则包含该两个实体的所有句子中，至少有一句在表达这个关系。他们将包含同一对实体的所有句子构成一个包，然后使用PCNN模型提取每个句子的表征，最后以包中概率最大的句子表征作为这个包的表征，通过Softmax进行分类。Lin&lt;sup&gt;[4]&lt;/sup&gt;等人则认为只使用包中最大概率的句子进行分类，会丢弃掉包中其他句子的有效信息，于是他们引入了句子级别的注意力，为包中每个句子赋予一个注意力权重，然后以包中所有句子表征的加权和作为这个包的表征。Lin等人的方法能够非常有效地降低远程监督所带来的标签噪声，现已成为基于远程监督的关系抽取中常用的Baseline了，许多学者在此基础上深入研究。&lt;/p&gt;
&lt;p&gt;另一种降低标签噪声影响的思路是提高模型的抗噪能力。Wu&lt;sup&gt;[5]&lt;/sup&gt;等人引入了对抗训练，以此增强模型对噪声数据的抵抗能力。&lt;/p&gt;
&lt;p&gt;虽然多实例学习和对抗训练可以降低标签噪声的影响，但并不能从根本上消除噪声。Feng&lt;sup&gt;[6]&lt;/sup&gt;等人借助强化学习模型，直接过滤掉训练样本中的噪声句子，然后使用剩下的训练数据来训练模型。Qin&lt;sup&gt;[7]&lt;/sup&gt;等人使用了生成对抗网络。他们使用生成器来划分数据，使用判别器来评价该划分的好坏，通过生成器和判别器的相互促进，最终得到一个能从训练集中筛选出噪声句子的生成器。&lt;/p&gt;
&lt;p&gt;上述工作虽然都在一定程度上降低了远程监督所带来的噪声影响，但仍局限于语料集本身，可用的信息只有文本统计的数据。近年来许多学者开始尝试借助外部知识的指导，进一步提高关系抽取模型的能力。Lei&lt;sup&gt;[8]&lt;/sup&gt;等人提出了协同降噪框架，利用知识图谱中的监督信息来降低远程监督的标签噪声。该框架使用两个神经网络分别在文本和知识图谱上学习，然后通过双向知识蒸馏模块完成它们之间的共同学习。Vashishth&lt;sup&gt;[9]&lt;/sup&gt;等人使用关系别名和实体类型这两种知识库信息来丰富了文本中的关系和实体信息。Xu&lt;sup&gt;[10]&lt;/sup&gt;等人通过知识图谱嵌入和关系抽取的联合学习，显著地提高了在远程监督下的关系抽取性能。&lt;/p&gt;
&lt;p&gt;除了借助外部知识的指导，还有学者在研究如何借助有监督下的关系抽取模型来指导远程监督下的关系抽取。然而现有的有监督数据集和远程监督数据集中的关系标签通常是不重合的，如何结合两种数据以提高远程监督下的关系抽取性能，是这个方向的首要任务。大多数的结合方法都是把两个数据集简单的混到一起，然后增加分类的类别。Beltagy&lt;sup&gt;[11]&lt;/sup&gt;等人则提出了更有效的结合方法，他们在有监督数据集上训练了一个二元关系分类器，判断句子是否表达了两个实体之间的关系，然后用此分类器来滤除远程监督样本中的假阳性噪声数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[1]   韩旭, 高天宇, 刘知远, et al. 知识图谱从哪里来：实体关系抽取的现状与未来[EB/OL]. 2019-11-7[2020-1-9]. &lt;a href=&#34;https://zhuanlan.zhihu.com/p/91762831&#34;&gt;https://zhuanlan.zhihu.com/p/91762831&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;[2]   Mintz M, Bills S, Snow R, et al. Distant supervision for relation extraction without labeled data[C]//Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009: 1003-1011.&lt;/p&gt;
&lt;p&gt;[3]   Zeng D, Liu K, Chen Y, et al. Distant supervision for relation extraction via piecewise convolutional neural networks[C]//Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015: 1753-1762.&lt;/p&gt;
&lt;p&gt;[4]   Lin Y, Shen S, Liu Z, et al. Neural relation extraction with selective attention over instances[C]//Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2016: 2124-2133.&lt;/p&gt;
&lt;p&gt;[5]   Wu Y, Bamman D, Russell S. Adversarial training for relation extraction[C]//Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017: 1778-1783.&lt;/p&gt;
&lt;p&gt;[6]   Feng J, Huang M, Zhao L, et al. Reinforcement learning for relation classification from noisy data[C]//Thirty-Second AAAI Conference on Artificial Intelligence. 2018.&lt;/p&gt;
&lt;p&gt;[7]   Qin P, Weiran X U, Wang W Y. DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction[C]//Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2018, 1: 496-505.&lt;/p&gt;
&lt;p&gt;[8]   Lei K, Chen D, Li Y, et al. Cooperative denoising for distantly supervised relation extraction[C]//Proceedings of the 27th International Conference on Computational Linguistics. 2018: 426-436.&lt;/p&gt;
&lt;p&gt;[9]   Vashishth S, Joshi R, Prayaga S S, et al. RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information[C]//Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018: 1257-1266.&lt;/p&gt;
&lt;p&gt;[10]  Xu P, Barbosa D. Connecting Language and Knowledge with Heterogeneous Representations for Neural Relation Extraction[C]//Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019: 3201-3206.&lt;/p&gt;
&lt;p&gt;[11]Beltagy I, Lo K, Ammar W. Combining distant and direct supervision for neural relation extraction[C]//Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019: 1858-1867.&lt;/p&gt;
</content>
            
            
            
            
            
                
                    
                
                    
                        
                            
                            
                            
                                <category scheme="https://tmliang.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/" term="关系抽取" label="关系抽取" />
                            
                        
                    
                
            
        </entry>
    
</feed>
